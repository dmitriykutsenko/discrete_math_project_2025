{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18ff64d2-c72c-4c2b-8a18-d1ae9d89654e",
   "metadata": {},
   "source": [
    "## Классификация распределения Pareto и распределения Exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d3418-2e2c-4ed1-ba9f-ae3b0321fad8",
   "metadata": {},
   "source": [
    "Для получения численных характеристик будем использовать дистанционный граф, так как в ходе прошлой части выяснили, что численные характеристики именно дистанционного графа лучше характеризуют распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbad5d65-4909-4f6d-a1cb-9c2fb21820c2",
   "metadata": {},
   "source": [
    "На данном этапе будем использовать все численные характеристики дистанционного графа:\n",
    "- Хроматическое число\n",
    "- Кликовое число\n",
    "- Размер максимального независимого множества\n",
    "- Число доминирования\n",
    "- Размер минимального кликового покрытия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04adf50-12cf-44da-92bb-f7096367fc14",
   "metadata": {},
   "source": [
    "Начнем с того, что соберем датасет с большим количеством симуляций построения нашего случайного графа, на котором мы будем учить нашу модель классифицировать распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4cdb821-62ee-4e5c-971c-9579848cd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.graph_builders import build_distance_graph\n",
    "from src.features import compute_feature\n",
    "from src.simulation import simulate_sample\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de06a4-0fc7-4a6c-89c8-504291d72168",
   "metadata": {},
   "source": [
    "Запустим процесс симуляции распределения и построения графа с подсчетом численных характеристик много раз и сохраним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e126ffbe-4c8c-4ba3-aff6-bbdaacc180d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767ceb2181574b208409bbdaa6d866b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация датасета для n = 100...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a687fea26d0140f78eb262269172394b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c49a7b2e414473952918ae619e6c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранен датасет: generated_data/distance_graph_features_n100.csv (размер: (5000, 6))\n"
     ]
    }
   ],
   "source": [
    "# Параметры эксперимента\n",
    "D = 1.5  # Фиксированный порог расстояния\n",
    "SAMPLE_SIZES = [25, 100, 500]  # Размеры выборок\n",
    "N_SAMPLES_PER_CLASS = {\n",
    "    25: 2500,\n",
    "    100: 2500,\n",
    "    500: 100\n",
    "}\n",
    "\n",
    "FEATURES = [\n",
    "    \"chromatic_number\",  # Хроматическое число\n",
    "    \"clique_number\",     # Кликовое число (размер максимальной клики)\n",
    "    \"max_independent_set\",  # Размер максимального независимого множества\n",
    "    \"domination_number\",    # Число доминирования\n",
    "    \"clique_cover_number\"   # Размер минимального кликового покрытия\n",
    "]\n",
    "\n",
    "# Параметры распределений\n",
    "alpha0 = 3.0                   # для распределения Парето\n",
    "lambda0 = 2.0 / np.sqrt(3.0)   # для экспоненциального распределения\n",
    "\n",
    "PARETO_PARAMS     = {\"alpha\": alpha0}\n",
    "EXPONENTIAL_PARAMS = {\"lam\": lambda0}\n",
    "\n",
    "def compute_graph_features(sample: np.ndarray) -> list:\n",
    "    G = build_distance_graph(sample, D)\n",
    "    return [compute_feature(G, feature) for feature in FEATURES]\n",
    "\n",
    "\n",
    "\n",
    "for n in tqdm([100]):\n",
    "    print(f\"Генерация датасета для n = {n}...\")\n",
    "    \n",
    "    features_data = np.zeros((N_SAMPLES_PER_CLASS[n] * 2, len(FEATURES)))\n",
    "    labels = np.zeros(N_SAMPLES_PER_CLASS[n] * 2)\n",
    "    \n",
    "    # pareto (класс 0)\n",
    "    for i in tqdm(range(N_SAMPLES_PER_CLASS[n])):\n",
    "        sample = simulate_sample(n, \"pareto\", PARETO_PARAMS)\n",
    "        features_data[i] = compute_graph_features(sample)\n",
    "    \n",
    "    # exponential (класс 1)\n",
    "    for i in tqdm(range(N_SAMPLES_PER_CLASS[n], N_SAMPLES_PER_CLASS[n] * 2)):\n",
    "        sample = simulate_sample(n, \"exponential\", EXPONENTIAL_PARAMS)\n",
    "        features_data[i] = compute_graph_features(sample)\n",
    "        labels[i] = 1\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(features_data, columns=FEATURES)\n",
    "    df['target'] = labels\n",
    "    \n",
    "    filename = f\"generated_data/distance_graph_features_n{n}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Сохранен датасет: {filename} (размер: {df.shape})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc42332-02b9-47d9-904f-01a87378c88d",
   "metadata": {},
   "source": [
    "Теперь рассмотрим 3 различных классификатора и обучим их. Использовать будем следующие классификаторы, которые позволяют интерпретировать значимость признаков:\n",
    "- Логистическая регрессия\n",
    "- Случайный лес\n",
    "- Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1267a4a4-89c8-48cd-b00b-4b49bf3ffbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем все нужное, чтобы учить классификаторы\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a7a9a3a-9d9d-4108-ac7c-b56103202dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m.\u001b[0m\n",
      "├── \u001b[1;36mconfusion_matrices\u001b[0m\n",
      "├── \u001b[1;36mfeature_importances\u001b[0m\n",
      "├── \u001b[1;36mgenerated_data\u001b[0m\n",
      "│   ├── distance_graph_features_n100.csv\n",
      "│   ├── distance_graph_features_n25.csv\n",
      "│   └── distance_graph_features_n500.csv\n",
      "├── pareto_exp_classification.ipynb\n",
      "└── pareto_exp_exploration.ipynb\n",
      "\n",
      "4 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a845bd-d77c-4e85-9d85-520b1100bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(n_size):\n",
    "    filename = f\"generated_data/distance_graph_features_n{n_size}.csv\"\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"Файл {filename} не найден! Сначала сгенерируйте данные.\")\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41b05d7-3d91-4206-abea-40640fd089f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, n_size):\n",
    "    results = []\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"CatBoost\": CatBoostClassifier(iterations=500, learning_rate=0.05, \n",
    "                                      depth=6, verbose=False, random_state=42)\n",
    "    }\n",
    "    \n",
    "    for i, (model_name, model) in enumerate(models.items()):\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Расчет метрик\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        \n",
    "        # Сохранение результатов\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Size': n_size,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6947dd4c-55be-4c97-920e-73a18c1f98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(models, feature_names, n_size):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for i, (model_name, model) in enumerate(models.items()):\n",
    "        if model_name == \"Logistic Regression\":\n",
    "            importances = np.abs(model.coef_[0])\n",
    "        elif model_name == \"Random Forest\":\n",
    "            importances = model.feature_importances_\n",
    "        elif model_name == \"CatBoost\":\n",
    "            importances = model.get_feature_importance()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        importances = 100.0 * (importances / importances.max())\n",
    "        sorted_idx = np.argsort(importances)\n",
    "        \n",
    "        plt.subplot(3, 1, i+1)\n",
    "        plt.barh(range(len(importances)), importances[sorted_idx], align='center')\n",
    "        plt.yticks(range(len(importances)), [feature_names[i] for i in sorted_idx])\n",
    "        plt.xlabel('Важность признака (%)')\n",
    "        plt.title(f'{model_name} - Важность признаков (n={n_size})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'feature_importances/feature_importance_n{n_size}.png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd57f69e-5655-4996-9717-ed3ba627491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Анализ для размера выборки n = 25\n",
      "==================================================\n",
      "\n",
      "Результаты для n=25:\n",
      "                 Model  Size  Accuracy  Precision  Recall        F1\n",
      "0  Logistic Regression    25     0.814   0.829832   0.790  0.809426\n",
      "1        Random Forest    25     0.814   0.835470   0.782  0.807851\n",
      "2             CatBoost    25     0.815   0.835821   0.784  0.809082\n",
      "\n",
      "==================================================\n",
      "Анализ для размера выборки n = 100\n",
      "==================================================\n",
      "\n",
      "Результаты для n=100:\n",
      "                 Model  Size  Accuracy  Precision  Recall        F1\n",
      "0  Logistic Regression   100     0.977   0.979879   0.974  0.976931\n",
      "1        Random Forest   100     0.977   0.979879   0.974  0.976931\n",
      "2             CatBoost   100     0.977   0.979879   0.974  0.976931\n",
      "\n",
      "==================================================\n",
      "Анализ для размера выборки n = 500\n",
      "==================================================\n",
      "\n",
      "Результаты для n=500:\n",
      "                 Model  Size  Accuracy  Precision  Recall   F1\n",
      "0  Logistic Regression   500       1.0        1.0     1.0  1.0\n",
      "1        Random Forest   500       1.0        1.0     1.0  1.0\n",
      "2             CatBoost   500       1.0        1.0     1.0  1.0\n",
      "\n",
      "Итоговые результаты по всем моделям и размерам выборок:\n",
      "                 Model  Size  Accuracy  Precision  Recall        F1\n",
      "0  Logistic Regression    25     0.814   0.829832   0.790  0.809426\n",
      "1        Random Forest    25     0.814   0.835470   0.782  0.807851\n",
      "2             CatBoost    25     0.815   0.835821   0.784  0.809082\n",
      "0  Logistic Regression   100     0.977   0.979879   0.974  0.976931\n",
      "1        Random Forest   100     0.977   0.979879   0.974  0.976931\n",
      "2             CatBoost   100     0.977   0.979879   0.974  0.976931\n",
      "0  Logistic Regression   500     1.000   1.000000   1.000  1.000000\n",
      "1        Random Forest   500     1.000   1.000000   1.000  1.000000\n",
      "2             CatBoost   500     1.000   1.000000   1.000  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Размеры выборок для анализа\n",
    "sample_sizes = [25, 100, 500]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for n_size in sample_sizes:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Анализ для размера выборки n = {n_size}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, scaler = load_and_prepare_data(n_size)\n",
    "    feature_names = [\"chromatic_number\", \"clique_number\", \n",
    "                    \"max_independent_set\", \"domination_number\", \n",
    "                    \"clique_cover_number\"]\n",
    "    \n",
    "    size_results = train_and_evaluate_models(X_train, X_test, y_train, y_test, n_size)\n",
    "    all_results.append(size_results)\n",
    "    \n",
    "    print(f\"\\nРезультаты для n={n_size}:\")\n",
    "    print(size_results)\n",
    "    \n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42).fit(X_train, y_train),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train),\n",
    "        \"CatBoost\": CatBoostClassifier(iterations=500, learning_rate=0.05, \n",
    "                                     depth=6, verbose=False, random_state=42).fit(X_train, y_train)\n",
    "    }\n",
    "    analyze_feature_importance(models, feature_names, n_size)\n",
    "\n",
    "final_results = pd.concat(all_results)\n",
    "print(\"\\nИтоговые результаты по всем моделям и размерам выборок:\")\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5630d7a1-c697-42c1-8730-e4198b2a805f",
   "metadata": {},
   "source": [
    "Как мы видим, все три модели показали хорошие результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2232c7-4001-489d-a0f7-d06aa35991c1",
   "metadata": {},
   "source": [
    "Сделаем выводы о вероятности ошибки первого рода и мощности построенных классификаторов, если рассматривать их как статистический критерий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e02400-7169-4d42-9c20-b4d5fcf95cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_statistical_metrics(X_test, y_test, models, n_size):\n",
    "    results = []\n",
    "    \n",
    "    # Создаем фигуру для матриц ошибок\n",
    "    fig, axes = plt.subplots(1, len(models), figsize=(5*len(models), 4))\n",
    "    if len(models) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    fig.suptitle(f'Матрицы ошибок (n={n_size})', fontsize=16)\n",
    "    \n",
    "    for i, (model_name, model) in enumerate(models.items()):\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        # Ошибка первого рода = P(отвергнуть H0|H0 верна) = FP / (FP + TN)\n",
    "        type1_error = fp / (fp + tn)\n",
    "        \n",
    "        # Мощность = P(отвергнуть H0|H1 верна) = TP / (TP + FN)\n",
    "        power = tp / (tp + fn)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Size': n_size,\n",
    "            'Type I Error': type1_error,\n",
    "            'Power': power\n",
    "        })\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                   xticklabels=['Pareto (H₀)', 'Exponential (H₁)'], \n",
    "                   yticklabels=['Pareto (H₀)', 'Exponential (H₁)'])\n",
    "        axes[i].set_title(f'{model_name}\\nType I: {type1_error:.4f}, Power: {power:.4f}')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('True')\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(f'confusion_matrices/statistical_metrics_n{n_size}.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c46cfd39-e646-40a5-8f34-db1ac8e0ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Статистический анализ для размера выборки n = 25\n",
      "==================================================\n",
      "\n",
      "Статистические метрики для n=25:\n",
      "                 Model  Type I Error  Power\n",
      "0  Logistic Regression         0.162  0.790\n",
      "1        Random Forest         0.154  0.782\n",
      "2             CatBoost         0.154  0.784\n",
      "\n",
      "==================================================\n",
      "Статистический анализ для размера выборки n = 100\n",
      "==================================================\n",
      "\n",
      "Статистические метрики для n=100:\n",
      "                 Model  Type I Error  Power\n",
      "0  Logistic Regression          0.02  0.974\n",
      "1        Random Forest          0.02  0.974\n",
      "2             CatBoost          0.02  0.974\n",
      "\n",
      "==================================================\n",
      "Статистический анализ для размера выборки n = 500\n",
      "==================================================\n",
      "\n",
      "Статистические метрики для n=500:\n",
      "                 Model  Type I Error  Power\n",
      "0  Logistic Regression           0.0    1.0\n",
      "1        Random Forest           0.0    1.0\n",
      "2             CatBoost           0.0    1.0\n",
      "\n",
      "Итоговые статистические метрики по всем моделям и размерам выборок:\n",
      "                 Model  Size  Type I Error  Power\n",
      "0  Logistic Regression    25         0.162  0.790\n",
      "1        Random Forest    25         0.154  0.782\n",
      "2             CatBoost    25         0.154  0.784\n",
      "0  Logistic Regression   100         0.020  0.974\n",
      "1        Random Forest   100         0.020  0.974\n",
      "2             CatBoost   100         0.020  0.974\n",
      "0  Logistic Regression   500         0.000  1.000\n",
      "1        Random Forest   500         0.000  1.000\n",
      "2             CatBoost   500         0.000  1.000\n"
     ]
    }
   ],
   "source": [
    "statistical_results = []\n",
    "\n",
    "for n_size in sample_sizes:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Статистический анализ для размера выборки n = {n_size}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, scaler = load_and_prepare_data(n_size)\n",
    "    \n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42).fit(X_train, y_train),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train, y_train),\n",
    "        \"CatBoost\": CatBoostClassifier(iterations=500, learning_rate=0.05, \n",
    "                                     depth=6, verbose=False, random_state=42).fit(X_train, y_train)\n",
    "    }\n",
    "    \n",
    "    size_stats = evaluate_statistical_metrics(X_test, y_test, models, n_size)\n",
    "    statistical_results.append(size_stats)\n",
    "    \n",
    "    print(f\"\\nСтатистические метрики для n={n_size}:\")\n",
    "    print(size_stats[['Model', 'Type I Error', 'Power']])\n",
    "\n",
    "final_stat_results = pd.concat(statistical_results)\n",
    "print(\"\\nИтоговые статистические метрики по всем моделям и размерам выборок:\")\n",
    "print(final_stat_results[['Model', 'Size', 'Type I Error', 'Power']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc34cc1-a849-4c0e-b5d5-5f08c0f531f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
